+ 现在就是在真实的环境里，一次完整的交互，其实不是那么的容易得到，一次怎么才能做到 不断进化的进行情感识别呢？？
+ 某些， 决策部分的神经元 怎么加进去
+ 用最简单的想法，就是每次成功的交互，会把此时的输入， 给进去，然后放在，交互结果对应的buffer中
+ 就用穿红色衣服去摸它吗？？ 慢慢的红色的脉冲输出就会被统计在 开心的buffer中， 所以就ok了？
  + 既要强化正确的buffer 还要弱化错误的buffer

+ 考虑到短期记忆和长期记忆的话



==============================================================================================

+ 输出的话， 可以使用比例做一个数据的强度，不只有一个分类的结果

+ 输入的话，如果是在线学习的话，可以把每一次成功的交互的过去的多个时间获取的输入，取个平均， 暂时是累计

+ 相当于准备一个线程，专门用来统计输入， 长度是5， 不断更新掉老的，每次成功交互后进行一次平均的归类

==============================================================================================

这两个类其实还挺ok的

==============================================================================================

+ 今天再拍一个 酒精的视频， 再把在线学习的逻辑跑一遍

==============================================================================================
+ Todo：
  + 把情感 到动作的那两个线程 再捋顺一点， 要方便实验

  + 大致思路是 红衣服过去，狗做一次下蹲
  + 红衣服过去 摸， 还是下蹲
  + 摸了一定次数 开始摇头

+ Todo：
  + 现在似乎可以达到了希望的效果，但是如果深入进去会发现，由于我预训练的原因，导致某一种情感的神经元全都具有所有的输入特征
  + 这显然是不合理的，因此可能要重新预训练，或者是输入完全分离预训练，或者是 引入一定的比例预训练
  + 先拍个视频，问问专利的事

+ 使用 完全独立的输入分离预训练后的single test 可以发现很明显的一点就是，数量少的情感输入（比如 抚摸我只给了一个），的脉冲发放时刻要更靠后我这里2.6s，
+ 这里理解起来也就是 输入强度低， 因此需要基类更久的信号才能脉冲
+ 而红色输入，我这里给了两个输入，就会有更快的脉冲 1.2s
+ 因此结果就是 当他们混合输入的时候， 先脉冲的会将后脉冲的 抑制住，这么弄的话， 我的负面抑制buffer 不久不起作用了吗
+ 或者说这里 的抚摸 真的不该当作输入参数吗？？？？？ 就完全当作 交互 的判定信号

+ 我再测试一下 综合输入的情况
+ 发现还是差不多，抚摸和红色同时输入时，抚摸基本是碾压的， 因此其实抚摸最好还是作为和指令交互一样的 进行交互判定的输入，而不是状态输入

+ Todo：
  + 把imu 改成 交互标志位的情况下，还需要再测试一下
  + 调试完成, 这种正向修正, 反向修正, 正向强化的调节机制要比之前顺畅得多
  + 发现一个有意思的点，就是由于前向传播后面还有一层的连接，因此我目前的侧向抑制 往往留有了一个时间步的间隙， 也就相当于留有了 一个其他神经元的脉冲空间
  + 不知道， 会不会有用

+ Todo：
  + 看看相关论文， 尝试手动编译工具
  + 将stdp和特殊lif放到 darwin3上应该还是挺麻烦的 感觉可能得慢慢来
  + 先用spaic实现一个超级简单的分类任务，然后把这个分类任务编译出来试一下， 行的化，再去尝试stdp 的神经元和学习方式
  + 先不使用嵌套，只使用L2作为解码层



  + 输入 要怎么想办法 丰富一下
  + 输出 要怎么多样化一点
  + 评价指标，图像
  + 和强化学习做对比还是挺重要的
  + 如果手动工具要做很久的话，就先把别的内容写出来吧，需要工作量的内容，早晚都要做
  + 接下来就是看自定义神经元的实现
+ spaic 的 stdp权重更新方式还挺有意思的， 输出脉冲* 输入trace - 输入脉冲*输出trace 
  + 细细品味，确实很有stdp的味道， 但是还不知道出处是哪里
---
+ darwin3 有 26 个控制寄存器， 6个状态寄存器，16个运行寄存器
  + load 把存储器读到寄存器
  + store 把寄存器读到存储器
  + 问一下前几个汇编的含义 和 自定义神经元
  + 问一下树突轴突
  + 问一下，如果要更新权重 的 NPC 函数
  + R3寄存器直接用的吗？？

+ 如果权重还不支持学习的话，想一想其他方法，或者有哪些是可以修改的，比如阈值？，比如我外部的buffer
+ 现在看起来的话，似乎可以把不同神经元 config 放到 不同的核心上
+ 现在就想着怎么操作一下， 也就是这两个lif 的量化的问题， 先试一下 alif， 把所有的值都改成正数
+ lifex 行的话， lif ih也没问题

+ 先试一下，把衰减阈值去掉之后，stdp是否能正确训练？进而验证出阈值衰减的必要性？？？
+ 在手写体里面，阈值的变化确实很夸张，原本是-52，一顿强化之后竟然达到了 -27， 接近一半 才触发下一个模式的脉冲
+ 每次增长0.05 的 vth_theta 增长到了 1.9
+ 有一个疑问，每次spaic input 输入的时候 神经元的电压会进行重新的 更新吗
+ 在darwin上，有个地方需要注意 就是 我的模电压 25个时间 后 会重新 赋值一次，类似于 spaic中的 下一个timestep
  + 这里感觉 得用 jmp 来做，就是当到了 25 的倍数的时候，就要对某些变量清零一次然后加载回 存储器
+ 而 vth_theta 似乎才是 最正统的每次都要 保存，测试了一下感觉没问题？？ 但是阈值和电压是负数 在darwin3 上可能还要在测试一下 Todo


+ 先测试 重置阈值正不正确                 --0   重置阈值是ok的
+ 所以接下来的话，先测试，负数阈值能不能做  --1   电压阈值设置成负数也是ok的
+ 再测试写一个带vth_theta 的 lif          --2   用jmp 搞定了简单的阈值自适应
+ 再用jmp 一定时间步进行清空               --3  Todo   只有电压需要清空
+ stdpex stdpih 分别测试                  --4  就是LIF
+ 连接起来测试                           --5   Todo

---


+ 现在的话就是去实现，stdp更新input到layer1层的连接

+ LSLS 是存取学习状态
+ UPTLS 是 用来更新 四个输入、输出迹 的公式， 更新学习状态
+ LSSYN 存取权重
+ UPTSYN 

PRT1A-X PRT1A-Y  输入脉冲迹

PRT1B-X PRT1B-Y 输出脉冲迹

PRT0-X PRT0-Y 奖惩参数，也就是常量

PRTR 

WPAR0 - WPAR15


问题，参数更新过程，比如权重和的更新是在哪里进行的呢， 那么迹的更新是在哪里进行的呢？

手册里指到的 "脉冲迹"， 是脉冲次数的和？还是什么定义？



+ 先配置好 lpar0-lpar6 作为trace 计算的参数  WPAR0 - WPAR1516个寄存器作为权重更新参数


LSLS 加载所有迹 1Ax 1Ay 1bx 1by 0x 0y  (0r 1r) 
UPTLS 使用迹 和 lpar 寄存器的参数计算 得到新的 1Ax 1Ay 1bx 1by r  这里相当于对迹进行了一些操作
LSLS 把迹存回去

LSSYN 读取权重 到权重寄存器
UPTSYN 更新权重
LSSYN 把权重存回去

---


怎么优化一下dmx 的输入和输出

---


+ 先解决2.4版本的runtime问题 是文件缺失的原因 

+ 每次都重启，要不然不干净


+ 学习 npc 调试ok 要进一步尝试把代码放进去了
  + 试一下三个npc里面的跳转
  + 其余的再说吧，先放假喽

+ 查到了有256 个树突 每个树突100个连接，但是 我只给一个输入层神经元有输入， 也就应该是 一个树突 有输入脉冲， 但怎么有两个 位置 是8000 呢


---


问题 1 ：
  + 怎么查看所有的学习状态存储器（迹）
  + UPTSYN todo 写的对不对
  + 权重怎么读出来， 如果不能读出来，权重就没办法可视化
  + 为什么要有奇偶时间步呢

Todo:
  + 迹的衰减 可能要处理一下，
  + 权重读取与可视化
  + ppt 中的那个 迹的衰减是怎么做出来的呢

+ 迹的衰减可以自动进行
+ 学习状态寄存器 reset 重置一下


Debug:
  + 迹测试的时候[0 1 0 0 0 0 0 0 0 0 ] 这么写不对，一个 0 就代表一个输入了， 如果是第三个  应该写成 [[3]], 就ok 了要不测试总出现 dfff 和 dffe 是 8000 真服了奥

---

Todo:
  + 移位实现迹的衰减 08配置寄存器 写不到, 手动改写
  + 每个大周期 要清空 trace 吗 ： 要！

Todo:
  + 权重已经能读出来了，现在的话，要用spaic-stdp 的同样的方式 plot 一下，方便之后 做对比， 观察训练的效果

Todo：
  + 权重也已经可以画出来了，但是现在发现，学习的权重不发生任何变化，暂时觉得有可能有两个原因
  1. 权重更新系数太小
  2. 迹太小，

  把权重的变化调出来试一试

Todo:
  + 权重可以更新了，但是参考spaic的实现，应该还缺少一步归一化操作， 看看怎么能实现
  + 还有就是 向神经科学参考一些内容，看看能不能把输入层也放到darwin3上，每一种传感器放在一个单独的核心中， 这样会更复杂和仿生度更高
  + 并且，记忆部分可不可以做在达尔文上，应该也可以用很多核心，然后，如果训练的时候，这块能直接训练出来就更好了
  + 当然问题要拆解成，先放上去，再考虑训练出来
  
Todo：
  + 感觉归一化的一个感觉是 侧向抑制没有成功，第二个是 时间不加长试一试
  + 想要实现训练，应该不是这么容易，可能得自己加一些新的东西
  + 也要再去梳理一下原算法的设计 
  + 有的输入一上来就脉冲了， 这个不应该的， 或者 脉冲那么多个 神经元 也不合理， 这个问题挺大
  
Todo：
  + 肯定一个就是怎么把图像画的好看，也就是怎么把darwin的这个可视化的图做好，（在darwin上训练）
  + 然后就是顺带着怎么扩充一下达尔文的维度
  + 原算法是怎么区分 使同一个神经元只对一种输入敏感的呢
  + 还有可能是我更新的速度太快了，导致没有分化出，不同输入的神经元

Todo：
  其实不应该在darwin3上太纠结了，应该从论文的整体交互或者其他地方进行优化

Todo:
  + 确实，感觉要想要项目更有说服力的话，应该是要从机器狗的整体的交互入手，再做的灵活一点才行
  + 此外的话，感觉可以把摄像头的利用再搞一搞，要不然没怎么利用有点可惜
  + 然后就是大模型，总共就是这两个地方
  + 感觉 python 的那个语音流不知道能不能做并行

感觉还是跳不过去保存文件那一步，但是发现好像可以检测声音大小，然后进行一个唤醒

Todo:
  + 可以把声音的图像动态的画出来了，接下来想着怎么做一个滑动窗口，然后也可以做并发？

用状态机也算是实现了 语音输入的更合理的检测

Todo：
  + python 有一个FER的库可以做视觉的人脸的情感识别，底层还是训练的网络，可能 可以用
  + 联想的话， 感觉其实可以做一个简单的 用snn人脸识别的， 都不用是情感识别，只要能识别出主人，我觉得就ok了


Todo:
  + 之前一直在 input_func 之中 减小发放的概率 否则  很多 激活层神经元都会脉冲, 其实是因为 阈值没有经过放大导致的, 并且 -20 和 -120 是不是 也要放大一下才好

  ```python
    def input_func(input_ls, unit_conversion=0.4, dt=0.1):# 这连个参数对标spaic的possion_encoder
      # 这里加了一层 随机性, 但其实还是要在 阈值放大来看,而不是 在这里一度的缩小
      a = (np.random.rand(*input_ls.shape) < input_ls * unit_conversion * dt) # a 是一个 true 和 false 的同维度 array
      return np.nonzero(a[0].astype(int))[0] # 返回一个 nozero 的 list  这里体现除了 darwin 的输入特点， 只对需要的内容 输入， 0代表的是 0 号神经元输入，
  ```
  + todo 也就是 考虑一个 阈值 和 后两层 权重  的 放大方式
    
  

---



> 现提交一版代码， 这一版代码是可以看到stdp 权重变化的， 但有一些地方需要注意：


  + 首先是 达尔文的 9 号精度寄存器 需要手动修改

```cpp
    core_config.set_register("CR_QA", (0x4 << 8)) 
    # 状态更新阶段精度 16位 随机取整 *15/16 右移 4位  
    # 这里要 将 0-2 config.dwnc 中该称 0 write 0 2 0x0008 0x00000400 
```

  + 其次是 stdp 算法的参数, 改成 +1 和 -1 ，当然其他参数也可以，但暂时 用的这个, 强化的 效果还行

```cpp
    core_config.set_register("CR_WPARA", 0x01 | int(hex((-1 & 0xff)<<8), 16)) # wpar0 = 1 wpar1 = -1 # 这里的5 和 -5 应该改成 1 1奥 
```

  + 第三个要注意的是 timestep 时钟周期，main_model_learn.py 中的 编译使用的 time_step 要和 真正运行时的 range 中的数值保持一致

```python
def step():
    ls = np.zeros(100,)
    test.clear_neurons_states(LSC=True)
    for _ in range(25):                   # 说的是这里
        input_ls = np.array([[1 if i==1 or i == 4 else 0.01 for i in range(16)] * 16])
        a = input_func(input_ls)
        # print(a)

        out = test.run_darwin3_withoutfile(spike_neurons=[a])
        
        for i in range(len(out[0])):
            index = out[0][i][1]
            ls[index] += 1 
    print(ls.nonzero())
```

  + 最后一个地方是，泊松编码输入的地方, 其中有一个缩放系数 unit_conversion , 其实这里是由于 阈值没放大正确, 放大了的话, 这里的作用应该只是, 调节脉冲的稀疏程度, 目前的参数使用的是 0.8

```python
    def input_func(input_ls, unit_conversion=0.8, dt=0.1):
```



---




Already_do:
  + 又做了两个修改，第一个是把神经元之间的 分别量化 改成了，全局的统一量化， 写到了论文里， 这里神经元之间的噪声应该是少了

  + 还有一个修改是，抑制层的神经元参数没有被 和 权重 同等放大 
    + 按照道理来说， 只需要将 第C_1权重，第一层神经元参数、反馈链接C_3的权重、同比放大即可，但是最后一层由于原本是 -120 已经是 8位有符号的最大值了， 所以 只能又把 C_2 的权重 放大了 5倍 作为补偿，
      所以最后的效果 其实要比 上一版要稳定 ， 这也就导致了 抑制层 更容易发放脉冲， 进而把抑制作用的效果 找补了回来

  +  这里可以试一下，+20 和 -20 的权重
  


+ Todo
  + 补充一点，之前之所以要 分成 不同 server 的原因 是因为 环境 导致的
